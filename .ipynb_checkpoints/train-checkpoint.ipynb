{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading = np.load('reading_np.npy')\n",
    "phn = np.load('phone_np.npy')\n",
    "drinking = np.load('drinking_np.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reading = np.full(50,0)\n",
    "y_phn = np.full(50,1)\n",
    "y_drink = np.full(50,2)\n",
    "Y = np.concatenate((y_reading, y_phn, y_drink), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = Y.shape[0]\n",
    "\n",
    "N_actions = 3\n",
    "N_features = 16380\n",
    "dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = np.zeros((N, N_actions))\n",
    "one_hot_labels[np.arange(N), Y] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((phn,reading,drinking))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 98, 140, 126,   9,   1,  35, 104,  12, 106, 147, 120, 105,  46,\n",
       "        39, 118, 139,  79, 142,  16, 122, 143, 123,  71, 115,   8,   4,\n",
       "        82, 114,  95,  80,  83,  91,  87,  60,  44,  73,   0,  18,  27,\n",
       "        75, 134,  25, 128,  90,  89,  20,  36, 108,  68,  76, 141,  94,\n",
       "        56,  23,  22,  65,  78,  37,  64,  88, 103,  96, 137,  19, 102,\n",
       "       146,  61,  10,   6,  34,  54, 136,  49,  85,  97,  51,  21,  47,\n",
       "        70,   7,  57,  58, 109,  74, 148, 131,  52,  99, 112,  14,  84,\n",
       "       101,  28,  53,  11, 149, 127,  63,  93,  24,  55,  86, 117,  13,\n",
       "        32,   3,  59,  29, 132, 135,  41, 125,  15,  69,  81,  48,  77,\n",
       "       129, 133, 110, 144, 121,  17,  45,  31, 113, 145, 119,   5, 138,\n",
       "         2,  62,  40, 130, 116,  67,  50,  92, 100,  72,  42,  38, 111,\n",
       "        66, 107,  26, 124,  30,  43,  33])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.arange(X.shape[0])\n",
    "np.random.shuffle(s)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_x = X[s]\n",
    "shuffled_y = Y[s]\n",
    "train_x = shuffled_x[0:int(0.8*N)]\n",
    "train_y = shuffled_y[0:int(0.8*N)]\n",
    "test_x = shuffled_x[int(0.8*N):]\n",
    "test_y = shuffled_y[int(0.8*N):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 16380])\n"
     ]
    }
   ],
   "source": [
    "train_x = torch.from_numpy(train_x)\n",
    "ffw_train = train_x.view(train_x.shape[0],-1)\n",
    "print(ffw_train.shape)\n",
    "mean = ffw_train.mean(dim=0)\n",
    "std = ffw_train.std(dim=0)\n",
    "ffw_train = (ffw_train - mean)/std\n",
    "ffw_train = ffw_train.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=16380, out_features=2048)\n",
      "  (fc2): Linear(in_features=2048, out_features=512)\n",
      "  (fc3): Linear(in_features=512, out_features=3)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(N_features,2048)\n",
    "        self.fc2 = nn.Linear(2048,512)\n",
    "        self.fc3 = nn.Linear(512,N_actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        #print(x.shape)\n",
    "        sft = nn.Softmax(dim=1)\n",
    "        x = sft(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = Variable(ffw_train).float()\n",
    "labels = Variable(torch.from_numpy(train_y))\n",
    "#labels = Variable(torch.from_numpy(one_hot_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.1030\n",
      "Epoch [2/100], Loss: 1.0129\n",
      "Epoch [3/100], Loss: 0.9343\n",
      "Epoch [4/100], Loss: 0.8989\n",
      "Epoch [5/100], Loss: 0.8779\n",
      "Epoch [6/100], Loss: 0.8623\n",
      "Epoch [7/100], Loss: 0.8496\n",
      "Epoch [8/100], Loss: 0.8385\n",
      "Epoch [9/100], Loss: 0.8288\n",
      "Epoch [10/100], Loss: 0.8201\n",
      "Epoch [11/100], Loss: 0.8123\n",
      "Epoch [12/100], Loss: 0.8052\n",
      "Epoch [13/100], Loss: 0.7984\n",
      "Epoch [14/100], Loss: 0.7919\n",
      "Epoch [15/100], Loss: 0.7858\n",
      "Epoch [16/100], Loss: 0.7801\n",
      "Epoch [17/100], Loss: 0.7749\n",
      "Epoch [18/100], Loss: 0.7702\n",
      "Epoch [19/100], Loss: 0.7659\n",
      "Epoch [20/100], Loss: 0.7619\n",
      "Epoch [21/100], Loss: 0.7582\n",
      "Epoch [22/100], Loss: 0.7549\n",
      "Epoch [23/100], Loss: 0.7520\n",
      "Epoch [24/100], Loss: 0.7495\n",
      "Epoch [25/100], Loss: 0.7475\n",
      "Epoch [26/100], Loss: 0.7457\n",
      "Epoch [27/100], Loss: 0.7442\n",
      "Epoch [28/100], Loss: 0.7429\n",
      "Epoch [29/100], Loss: 0.7417\n",
      "Epoch [30/100], Loss: 0.7406\n",
      "Epoch [31/100], Loss: 0.7394\n",
      "Epoch [32/100], Loss: 0.7384\n",
      "Epoch [33/100], Loss: 0.7373\n",
      "Epoch [34/100], Loss: 0.7362\n",
      "Epoch [35/100], Loss: 0.7351\n",
      "Epoch [36/100], Loss: 0.7340\n",
      "Epoch [37/100], Loss: 0.7329\n",
      "Epoch [38/100], Loss: 0.7319\n",
      "Epoch [39/100], Loss: 0.7310\n",
      "Epoch [40/100], Loss: 0.7301\n",
      "Epoch [41/100], Loss: 0.7294\n",
      "Epoch [42/100], Loss: 0.7287\n",
      "Epoch [43/100], Loss: 0.7280\n",
      "Epoch [44/100], Loss: 0.7275\n",
      "Epoch [45/100], Loss: 0.7270\n",
      "Epoch [46/100], Loss: 0.7266\n",
      "Epoch [47/100], Loss: 0.7263\n",
      "Epoch [48/100], Loss: 0.7260\n",
      "Epoch [49/100], Loss: 0.7257\n",
      "Epoch [50/100], Loss: 0.7254\n",
      "Epoch [51/100], Loss: 0.7251\n",
      "Epoch [52/100], Loss: 0.7249\n",
      "Epoch [53/100], Loss: 0.7246\n",
      "Epoch [54/100], Loss: 0.7244\n",
      "Epoch [55/100], Loss: 0.7242\n",
      "Epoch [56/100], Loss: 0.7240\n",
      "Epoch [57/100], Loss: 0.7238\n",
      "Epoch [58/100], Loss: 0.7236\n",
      "Epoch [59/100], Loss: 0.7234\n",
      "Epoch [60/100], Loss: 0.7232\n",
      "Epoch [61/100], Loss: 0.7231\n",
      "Epoch [62/100], Loss: 0.7229\n",
      "Epoch [63/100], Loss: 0.7228\n",
      "Epoch [64/100], Loss: 0.7226\n",
      "Epoch [65/100], Loss: 0.7225\n",
      "Epoch [66/100], Loss: 0.7224\n",
      "Epoch [67/100], Loss: 0.7223\n",
      "Epoch [68/100], Loss: 0.7222\n",
      "Epoch [69/100], Loss: 0.7220\n",
      "Epoch [70/100], Loss: 0.7219\n",
      "Epoch [71/100], Loss: 0.7218\n",
      "Epoch [72/100], Loss: 0.7217\n",
      "Epoch [73/100], Loss: 0.7216\n",
      "Epoch [74/100], Loss: 0.7215\n",
      "Epoch [75/100], Loss: 0.7214\n",
      "Epoch [76/100], Loss: 0.7213\n",
      "Epoch [77/100], Loss: 0.7212\n",
      "Epoch [78/100], Loss: 0.7210\n",
      "Epoch [79/100], Loss: 0.7209\n",
      "Epoch [80/100], Loss: 0.7207\n",
      "Epoch [81/100], Loss: 0.7205\n",
      "Epoch [82/100], Loss: 0.7203\n",
      "Epoch [83/100], Loss: 0.7201\n",
      "Epoch [84/100], Loss: 0.7199\n",
      "Epoch [85/100], Loss: 0.7197\n",
      "Epoch [86/100], Loss: 0.7195\n",
      "Epoch [87/100], Loss: 0.7194\n",
      "Epoch [88/100], Loss: 0.7193\n",
      "Epoch [89/100], Loss: 0.7192\n",
      "Epoch [90/100], Loss: 0.7191\n",
      "Epoch [91/100], Loss: 0.7190\n",
      "Epoch [92/100], Loss: 0.7189\n",
      "Epoch [93/100], Loss: 0.7189\n",
      "Epoch [94/100], Loss: 0.7188\n",
      "Epoch [95/100], Loss: 0.7187\n",
      "Epoch [96/100], Loss: 0.7186\n",
      "Epoch [97/100], Loss: 0.7186\n",
      "Epoch [98/100], Loss: 0.7185\n",
      "Epoch [99/100], Loss: 0.7185\n",
      "Epoch [100/100], Loss: 0.7184\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "        # Convert torch tensor to Variable\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(train_x.cuda())\n",
    "        outputs = outputs\n",
    "        loss = criterion(outputs, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print ('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    out = net(x)\n",
    "    weight, action = torch.max(out, dim=1)\n",
    "    return action.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x,labels):\n",
    "    N = labels.shape[0]\n",
    "    predicted = pred(x.cuda())\n",
    "    i = 0\n",
    "    for yhat,y in zip(predicted,labels):\n",
    "        \n",
    "        if yhat == y:\n",
    "            i += 1\n",
    "    print('Accuracy:', i*100/N)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 16380])\n"
     ]
    }
   ],
   "source": [
    "test_x = torch.from_numpy(test_x)\n",
    "ffw_test = test_x.view(test_x.shape[0],-1)\n",
    "print(ffw_test.shape)\n",
    "mean = ffw_test.mean(dim=0)\n",
    "std = ffw_test.std(dim=0)\n",
    "ffw_test = (ffw_test - mean)/std\n",
    "ffw_test = ffw_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.66666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy(Variable(ffw_test), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
