{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading = np.load('reading_np.npy')\n",
    "phn = np.load('phone_np.npy')\n",
    "drinking = np.load('drinking_np.npy')\n",
    "cleaning = np.load('cleaning_np.npy')\n",
    "walking = np.load('walking_np.npy')\n",
    "cutting = np.load('cutting_np.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reading = np.full(50,0)\n",
    "y_phn = np.full(50,1)\n",
    "y_drink = np.full(50,2)\n",
    "y_cleaning = np.full(50,3)\n",
    "y_walking = np.full(50,4)\n",
    "y_cutting = np.full(50,5)\n",
    "Y = np.concatenate((y_reading, y_phn, y_drink, y_cleaning, y_walking, y_cutting), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = Y.shape[0]\n",
    "\n",
    "N_actions = 6\n",
    "\n",
    "dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = np.zeros((N, N_actions))\n",
    "one_hot_labels[np.arange(N), Y] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((phn,reading,drinking,cleaning,walking,cutting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = frameMat\n",
    "\n",
    "nums_skeleton = 20\n",
    "n_frames = 273\n",
    "frameMat_temp = np.zeros((n_frames, n_features))\n",
    "for i in range(n_frames):\n",
    "    Origin = (temp[i, 12:15] + temp[i, 15:18] + temp[i, 18:21]) / 3\n",
    "    for j in range(num_joints):\n",
    "        index = 3*j\n",
    "        frameMat_temp[i, index] = temp[i, index] - Origin[0]\n",
    "        frameMat_temp[i, index + 1] = temp[i, index + 1] - Origin[1]\n",
    "        frameMat_temp[i, index + 2] = temp[i, index + 2] - Origin[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X.mean(axis= 0)\n",
    "std  = X.std(axis = 0)\n",
    "X = (X - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(X.shape[0])\n",
    "np.random.shuffle(s)\n",
    "shuffled_x = X[s]\n",
    "shuffled_y = Y[s]\n",
    "train_x = shuffled_x[0:int(0.8*N)]\n",
    "train_y = shuffled_y[0:int(0.8*N)]\n",
    "test_x = shuffled_x[int(0.8*N):]\n",
    "test_y = shuffled_y[int(0.8*N):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = Variable(torch.from_numpy(train_x)).float()\n",
    "test_x = Variable(torch.from_numpy(test_x))\n",
    "test_x = test_x.float().cuda()\n",
    "labels = Variable(torch.from_numpy(train_y))\n",
    "test_y = Variable(torch.from_numpy(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240, 273, 20, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 273, 20, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size):\n",
    "        super(ActionNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2label = nn.Linear(SEQ_LENGTH*hidden_dim, label_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim)).cuda(),\n",
    "                autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim)).cuda())\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y  = self.hidden2label(lstm_out.view(BATCH_SIZE,-1))\n",
    "        log_probs = F.softmax(y, dim=1)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 60\n",
    "HIDDEN_DIM = 32\n",
    "SEQ_LENGTH = train_x.shape[1]\n",
    "LABEL_SIZE = N_actions\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "num_batches = train_x.shape[0]/BATCH_SIZE\n",
    "num_test_batches = test_x.shape[0]/BATCH_SIZE\n",
    "net = ActionNet(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, label_size=LABEL_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "net = net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 5.9030, Test Loss: 3.6012\n",
      "Epoch [2/100], Loss: 1.1212, Test Loss: 0.6518\n",
      "Epoch [3/100], Loss: 0.3224, Test Loss: 0.4267\n",
      "Epoch [4/100], Loss: 0.1761, Test Loss: 0.3647\n",
      "Epoch [5/100], Loss: 0.0723, Test Loss: 0.2923\n",
      "Epoch [6/100], Loss: 0.0344, Test Loss: 0.2655\n",
      "Epoch [7/100], Loss: 0.0252, Test Loss: 0.2770\n",
      "Epoch [8/100], Loss: 0.0207, Test Loss: 0.2801\n",
      "Epoch [9/100], Loss: 0.0162, Test Loss: 0.2682\n",
      "Epoch [10/100], Loss: 0.0137, Test Loss: 0.2564\n",
      "Epoch [11/100], Loss: 0.0121, Test Loss: 0.2500\n",
      "Epoch [12/100], Loss: 0.0109, Test Loss: 0.2478\n",
      "Epoch [13/100], Loss: 0.0099, Test Loss: 0.2476\n",
      "Epoch [14/100], Loss: 0.0091, Test Loss: 0.2475\n",
      "Epoch [15/100], Loss: 0.0084, Test Loss: 0.2468\n",
      "Epoch [16/100], Loss: 0.0077, Test Loss: 0.2455\n",
      "Epoch [17/100], Loss: 0.0071, Test Loss: 0.2438\n",
      "Epoch [18/100], Loss: 0.0066, Test Loss: 0.2420\n",
      "Epoch [19/100], Loss: 0.0062, Test Loss: 0.2404\n",
      "Epoch [20/100], Loss: 0.0057, Test Loss: 0.2389\n",
      "Epoch [21/100], Loss: 0.0054, Test Loss: 0.2375\n",
      "Epoch [22/100], Loss: 0.0050, Test Loss: 0.2363\n",
      "Epoch [23/100], Loss: 0.0047, Test Loss: 0.2351\n",
      "Epoch [24/100], Loss: 0.0044, Test Loss: 0.2339\n",
      "Epoch [25/100], Loss: 0.0042, Test Loss: 0.2328\n",
      "Epoch [26/100], Loss: 0.0039, Test Loss: 0.2316\n",
      "Epoch [27/100], Loss: 0.0037, Test Loss: 0.2305\n",
      "Epoch [28/100], Loss: 0.0035, Test Loss: 0.2295\n",
      "Epoch [29/100], Loss: 0.0033, Test Loss: 0.2285\n",
      "Epoch [30/100], Loss: 0.0032, Test Loss: 0.2274\n",
      "Epoch [31/100], Loss: 0.0030, Test Loss: 0.2265\n",
      "Epoch [32/100], Loss: 0.0029, Test Loss: 0.2255\n",
      "Epoch [33/100], Loss: 0.0027, Test Loss: 0.2246\n",
      "Epoch [34/100], Loss: 0.0026, Test Loss: 0.2237\n",
      "Epoch [35/100], Loss: 0.0025, Test Loss: 0.2228\n",
      "Epoch [36/100], Loss: 0.0024, Test Loss: 0.2219\n",
      "Epoch [37/100], Loss: 0.0023, Test Loss: 0.2211\n",
      "Epoch [38/100], Loss: 0.0022, Test Loss: 0.2202\n",
      "Epoch [39/100], Loss: 0.0021, Test Loss: 0.2194\n",
      "Epoch [40/100], Loss: 0.0020, Test Loss: 0.2186\n",
      "Epoch [41/100], Loss: 0.0019, Test Loss: 0.2178\n",
      "Epoch [42/100], Loss: 0.0019, Test Loss: 0.2171\n",
      "Epoch [43/100], Loss: 0.0018, Test Loss: 0.2163\n",
      "Epoch [44/100], Loss: 0.0017, Test Loss: 0.2156\n",
      "Epoch [45/100], Loss: 0.0017, Test Loss: 0.2149\n",
      "Epoch [46/100], Loss: 0.0016, Test Loss: 0.2142\n",
      "Epoch [47/100], Loss: 0.0015, Test Loss: 0.2135\n",
      "Epoch [48/100], Loss: 0.0015, Test Loss: 0.2128\n",
      "Epoch [49/100], Loss: 0.0014, Test Loss: 0.2121\n",
      "Epoch [50/100], Loss: 0.0014, Test Loss: 0.2115\n",
      "Epoch [51/100], Loss: 0.0013, Test Loss: 0.2108\n",
      "Epoch [52/100], Loss: 0.0013, Test Loss: 0.2102\n",
      "Epoch [53/100], Loss: 0.0013, Test Loss: 0.2096\n",
      "Epoch [54/100], Loss: 0.0012, Test Loss: 0.2089\n",
      "Epoch [55/100], Loss: 0.0012, Test Loss: 0.2083\n",
      "Epoch [56/100], Loss: 0.0012, Test Loss: 0.2077\n",
      "Epoch [57/100], Loss: 0.0011, Test Loss: 0.2071\n",
      "Epoch [58/100], Loss: 0.0011, Test Loss: 0.2066\n",
      "Epoch [59/100], Loss: 0.0011, Test Loss: 0.2060\n",
      "Epoch [60/100], Loss: 0.0010, Test Loss: 0.2054\n",
      "Epoch [61/100], Loss: 0.0010, Test Loss: 0.2049\n",
      "Epoch [62/100], Loss: 0.0010, Test Loss: 0.2043\n",
      "Epoch [63/100], Loss: 0.0009, Test Loss: 0.2038\n",
      "Epoch [64/100], Loss: 0.0009, Test Loss: 0.2033\n",
      "Epoch [65/100], Loss: 0.0009, Test Loss: 0.2027\n",
      "Epoch [66/100], Loss: 0.0009, Test Loss: 0.2022\n",
      "Epoch [67/100], Loss: 0.0008, Test Loss: 0.2017\n",
      "Epoch [68/100], Loss: 0.0008, Test Loss: 0.2012\n",
      "Epoch [69/100], Loss: 0.0008, Test Loss: 0.2007\n",
      "Epoch [70/100], Loss: 0.0008, Test Loss: 0.2002\n",
      "Epoch [71/100], Loss: 0.0008, Test Loss: 0.1997\n",
      "Epoch [72/100], Loss: 0.0007, Test Loss: 0.1992\n",
      "Epoch [73/100], Loss: 0.0007, Test Loss: 0.1988\n",
      "Epoch [74/100], Loss: 0.0007, Test Loss: 0.1983\n",
      "Epoch [75/100], Loss: 0.0007, Test Loss: 0.1978\n",
      "Epoch [76/100], Loss: 0.0007, Test Loss: 0.1974\n",
      "Epoch [77/100], Loss: 0.0007, Test Loss: 0.1969\n",
      "Epoch [78/100], Loss: 0.0006, Test Loss: 0.1965\n",
      "Epoch [79/100], Loss: 0.0006, Test Loss: 0.1960\n",
      "Epoch [80/100], Loss: 0.0006, Test Loss: 0.1956\n",
      "Epoch [81/100], Loss: 0.0006, Test Loss: 0.1951\n",
      "Epoch [82/100], Loss: 0.0006, Test Loss: 0.1947\n",
      "Epoch [83/100], Loss: 0.0006, Test Loss: 0.1943\n",
      "Epoch [84/100], Loss: 0.0006, Test Loss: 0.1938\n",
      "Epoch [85/100], Loss: 0.0006, Test Loss: 0.1934\n",
      "Epoch [86/100], Loss: 0.0005, Test Loss: 0.1930\n",
      "Epoch [87/100], Loss: 0.0005, Test Loss: 0.1926\n",
      "Epoch [88/100], Loss: 0.0005, Test Loss: 0.1922\n",
      "Epoch [89/100], Loss: 0.0005, Test Loss: 0.1918\n",
      "Epoch [90/100], Loss: 0.0005, Test Loss: 0.1914\n",
      "Epoch [91/100], Loss: 0.0005, Test Loss: 0.1910\n",
      "Epoch [92/100], Loss: 0.0005, Test Loss: 0.1906\n",
      "Epoch [93/100], Loss: 0.0005, Test Loss: 0.1902\n",
      "Epoch [94/100], Loss: 0.0005, Test Loss: 0.1898\n",
      "Epoch [95/100], Loss: 0.0005, Test Loss: 0.1895\n",
      "Epoch [96/100], Loss: 0.0004, Test Loss: 0.1891\n",
      "Epoch [97/100], Loss: 0.0004, Test Loss: 0.1887\n",
      "Epoch [98/100], Loss: 0.0004, Test Loss: 0.1883\n",
      "Epoch [99/100], Loss: 0.0004, Test Loss: 0.1880\n",
      "Epoch [100/100], Loss: 0.0004, Test Loss: 0.1876\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    test_running_loss = 0\n",
    "    for batch in range(int(num_test_batches)):\n",
    "        x = test_x[BATCH_SIZE*batch:BATCH_SIZE*(batch+1)].view(SEQ_LENGTH,BATCH_SIZE,-1)\n",
    "        out = net(x)\n",
    "        loss = criterion(out,test_y[BATCH_SIZE*batch:BATCH_SIZE*(batch+1)].cuda())\n",
    "        test_running_loss += loss.data[0]\n",
    "    \n",
    "    test_loss_list.append(test_running_loss)\n",
    "    for batch in range(int(num_batches)):\n",
    "        x = train_x[BATCH_SIZE*batch:BATCH_SIZE*(batch+1)].view(SEQ_LENGTH,BATCH_SIZE,-1).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        net.hidden = net.init_hidden()\n",
    "        \n",
    "        out = net(x)\n",
    "        #print(out.shape)\n",
    "        loss = criterion(out,labels[BATCH_SIZE*batch:BATCH_SIZE*(batch+1)].cuda())\n",
    "        running_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss_list.append(running_loss)\n",
    "        \n",
    "    print ('Epoch [%d/%d], Loss: %.4f, Test Loss: %.4f' %(epoch+1, num_epochs, running_loss, test_running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph(y1,y2,x):\n",
    "    plt.plot(x,y1, label = \"Train loss\")\n",
    "    plt.plot(x,y2, label=\"Test Loss\")\n",
    "    plt.legend()\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f771d28abe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotGraph(train_loss_list, test_loss_list, [i for i in range(num_epochs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    out = net(x)\n",
    "    weight, action = torch.max(out, dim=1)\n",
    "    return action.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x,labels):\n",
    "    N = labels.shape[0]\n",
    "    predicted = pred(x.cuda())\n",
    "    i = 0\n",
    "    for yhat,y in zip(predicted,labels):\n",
    "        \n",
    "        if yhat == y:\n",
    "            i += 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 273, 20, 3])\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 273, 20, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Accuracy(x,y):\n",
    "    x = x.float().cuda()\n",
    "    n_testbatch = int(x.shape[0]/BATCH_SIZE)\n",
    "    n_correct = 0\n",
    "    for i in range(n_testbatch):\n",
    "        test_batch_x = x[i*BATCH_SIZE:(i+1)*BATCH_SIZE].view(-1,SEQ_LENGTH, BATCH_SIZE, EMBEDDING_DIM)\n",
    "        n_correct += accuracy(test_batch_x[0], y[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "    print(\"Accuracy :\", n_correct*100/x.shape[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 96.66666666666667\n"
     ]
    }
   ],
   "source": [
    "get_Accuracy(test_x,test_y.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.0\n"
     ]
    }
   ],
   "source": [
    "get_Accuracy(train_x, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
